{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/tripadviser_review.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rating'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/DLassn/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rating'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d7a7f1d417ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrating_to_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DLassn/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DLassn/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rating'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def apply_regular_expression(text):\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ 가-힣]')  # 한글 추출 규칙: 띄어 쓰기(1 개)를 포함한 한글\n",
    "    result = hangul.sub('', text)  # 위에 설정한 \"hangul\"규칙을 \"text\"에 적용(.sub)시킴\n",
    "    return result\n",
    "\n",
    "okt = Okt()  # 명사 형태소 추출 함수\n",
    "nouns = okt.nouns(apply_regular_expression(df['text'][0]))\n",
    "nouns\n",
    "stopwords = pd.read_csv(\"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/korean_stopwords.txt\").values.tolist()\n",
    "stopwords[:10]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def text_cleaning(text):\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ 가-힣]')  # 정규 표현식 처리\n",
    "    result = hangul.sub('', text)\n",
    "    okt = Okt()  # 형태소 추출\n",
    "    nouns = okt.nouns(result)\n",
    "    nouns = [x for x in nouns if len(x) > 1]  # 한글자 키워드 제거\n",
    "    nouns = [x for x in nouns if x not in stopwords]  # 불용어 제거\n",
    "    return nouns\n",
    "\n",
    "vect = CountVectorizer(tokenizer = lambda x: text_cleaning(x))\n",
    "bow_vect = vect.fit_transform(df['text'].tolist())\n",
    "word_list = vect.get_feature_names()\n",
    "count_list = bow_vect.toarray().sum(axis=0)\n",
    "\n",
    "word_count_dict = dict(zip(word_list, count_list))\n",
    "word_count_dict\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_vectorizer = TfidfTransformer()\n",
    "tf_idf_vect = tfidf_vectorizer.fit_transform(bow_vect)\n",
    "\n",
    "invert_index_vectorizer = {v: k for k, v in vect.vocabulary_.items()}\n",
    "\n",
    "def rating_to_label(rating):\n",
    "    if rating > 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df['y'] = df['rating'].apply(lambda x: rating_to_label(x))\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = tf_idf_vect\n",
    "y = df['y']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state=1)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# fit in training set\n",
    "lr = LogisticRegression(random_state = 0)\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "# predict in test set\n",
    "y_pred = lr.predict(x_test)\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confu = confusion_matrix(y_true = y_test, y_pred = y_pred)\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.heatmap(confu, annot=True, annot_kws={'size':15}, cmap='OrRd', fmt='.10g')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"first_article.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Vocabulary not fitted or provided",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5ad2ed1534bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtext_cleaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbow_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mword_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcount_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbow_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DLassn/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1265\u001b[0m                 \u001b[0;34m\"Iterable over raw text documents expected, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m                 \"string object received.\")\n\u001b[0;32m-> 1267\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DLassn/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_check_vocabulary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Vocabulary not fitted or provided\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: Vocabulary not fitted or provided"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(tokenizer = lambda x: text_cleaning(x))\n",
    "bow_vect = vect.transform(df['text'].tolist())\n",
    "word_list = vect.get_feature_names()\n",
    "count_list = bow_vect.toarray().sum(axis=0)\n",
    "\n",
    "word_count_dict = dict(zip(word_list, count_list))\n",
    "word_count_dict\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_vectorizer = TfidfTransformer()\n",
    "tf_idf_vect = tfidf_vectorizer.fit_transform(bow_vect)\n",
    "\n",
    "invert_index_vectorizer = {v: k for k, v in vect.vocabulary_.items()}\n",
    "\n",
    "x_feeds = tf_idf_vect\n",
    "\n",
    "# predict in test set\n",
    "y_pred = lr.predict(x_feeds)\n",
    "\n",
    "# confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     자기는 고졸에 행시로 여기까지 왔으면서  사다리 걷어차기! \n",
       "1                   국회의원 기본급 절반삭감, 활동비 없애기, 연금 폐지부터 해라 \n",
       "2     난 김동연 이사람이 참 합리적인 사람으로보여.근디 혼자서는 힘든데.그래도 윤씨나 최...\n",
       "3     공무원 정년 폐지...ㅋ 아예 국회의원 임기 폐지 들고 나오지  젊은 세대 죽어 나...\n",
       "4                      건들지 말아야 할 공직사회를 건드리시다니...용감합니다. \n",
       "5     김동연화이팅!!!! 이런 사람이 많이 나와서  대한민국을 바꾸어 놓아야 하는데  아...\n",
       "6       ●공무원 철밥통은 깨야한다. ●공무원의 복지부동이 나라 밍친다. ●꼬옥~실천해주세요 \n",
       "7             이분은 그래도 양심과 도덕적이지 윤석열 최재형 은 직을 이용해 출세하려고 \n",
       "8     직급 계급 건너뛰는 제도 전부 없애라 사관학교  경찰대  7급 5급  외시 행시 없...\n",
       "9     실망이다  국민들은  힘들고 어려운데 공무원이 너무많고 예산 낭비다.  국민을 생각...\n",
       "10                             이런 공약이 제대로 이행되어야 나라가 산다 \n",
       "11                                      뭐  애들 대통놀이 하니? \n",
       "12     폐지가 맞다.  행정고시도  사법고시와 똑 같다.  순기능 보다는 악기능이 더 많다. \n",
       "13                                    공무원 정년 없애면 어떡하니? \n",
       "14                                         집에가서 잠이나 자라 \n",
       "15                                       화이팅. 청와대로 보내자 \n",
       "16                  넌 안된다는거 알면서도 왜 나오는거냐? 스스로도 알텐데 말이야 \n",
       "17    김동연 자신도 행정고시를 통해서... 5급 공무원으로 공직을 시작했는데... 그로부...\n",
       "18       니가할말이 아니다  넌 행시혜택보고 이자리까지왔으면서 젊은이들  사다리를 걷어차냐 \n",
       "19    지가 정년이 끝나니 ㅋㅋㅋ 다 해먹고 자식들은 유학보내 스펙 키워놓고 ㅋㅋㅋ 진심 ...\n",
       "20    공무원 개혁은 좋습니다. 그러나 윗대가리를 주터 하세요.  잘못은 정치인, 운영을 ...\n",
       "21    본인은 행시로 누릴거 다 누리고 국비로 유학까지 다녀온거 같은데  퇴직하고 친정에 ...\n",
       "22                         뭔소리야... 우리 청년들 밥줄 끊겠다는 소리잖아 \n",
       "23                        자기는 혜택 다보고  이제 후배들 죽인다고  별로다 \n",
       "24    국회의원 너무 많습니다. 도시 하나에 구로 쪼게지먄 동네방네 늘어난 국회의원 수 지...\n",
       "25    사다리를 걷어찬다는소리군 자기도 입법 행정고시출신이면서 그거없이 그자리를 어떻게 가...\n",
       "26                            공무원보다 현 정치인 부터 개혁이 필요하다. \n",
       "27                                          석열이 보단 훨낫네 \n",
       "28                                      지는 다 해쳐먹고 없앤다네 \n",
       "29            굿!!! 공무원 연금, 군인 연금, 군인 혜택도 모두 상식선으로 줄이자. \n",
       "30    난세의 영웅......덕수상고 야간출신......흙수저 김동연!!!!  김동연대통령...\n",
       "31                                     어차피 안되니깐 막 질러줘라 \n",
       "32    지는 혜택 다 받고있고 받았으면서 공무원 건드는 것이 공약이냐  그래야 국민들이 좋...\n",
       "33                   잘하는것이다 김동연 후보~~~ 공무원 철밥통 반드시 깨야한다 \n",
       "34    대한민국 집값 상승의 주범이 김동연인데…. 이자를 찬영하는 모지리들도 있나보네 ㅋㅋ...\n",
       "35              본인도 공직자 생활을 하신분인데 이런말을 하시다니 용기있는 분이시네. \n",
       "36    첫번째 공약이 공무원 철밥통 깨기? 나쁘지 않지만  1호 공약이라니 너무 비젼이 없...\n",
       "37                                       공무원  축소 ~  찬성 \n",
       "38    야당 국힘당 후보 다 사퇴하고  국힘당도 해체하고 그냥 김동연에 들어가라 야당 국힘...\n",
       "39    공무원 신분보장 조항이 왜 있는지 모르네...부당한 압력에 저항해도 일신에 문제가 ...\n",
       "40                          사회를 바뀌려는 김동연 후보님 생각에 공감갑니다 \n",
       "41    공뭔수 줄여야 하는거 맞아요. 넘 놀아요. 일이 없어서~ 철밥통도 없어져야 할 적폐죠! \n",
       "42    인구감소가 가속화되는 가운데 공무원의 숫자를 줄이는 정책은 큰틀에서 볼때 이뤄져야함...\n",
       "43                            정밀!!좋은공약이다~!!!!적극찬성합니다^^ \n",
       "44    우와~이거 최고의 정책인걸.. 나 김동연이 겁나 욕하고 싫어하는 인간 부류인데.. ...\n",
       "45    그게 급한게 아니야 X마~~~  청년들이 힘을 낼 수 있는 정책을 내놔봐!  이 나...\n",
       "46                    헌정권  비판도 못하면서...말초적인것으로  선동하는게.. \n",
       "47    성과평과 잘 받으려고 줄서기 시작하며 더 상명하복 되것네 일이 없어 소멸한다면 없는...\n",
       "48    공무원 체질개선 많이 늦었지만 지금이라도 한다면 대찬성입니다. 공무원, 공사, 관리...\n",
       "49    국가경쟁력 말아먹을려고 작정했구나~~  공공행정체계가 문제가 아니라 지금 민간경제중...\n",
       "50                             공무원 때리면 당선될거라 보는거냐? 안일해 \n",
       "51    그럼 나라  중요 일은 누가하고 9급 출신들이 중요 나라 업무 할수있나 능력있는사람...\n",
       "52                                사법고시는 왜 말 안하냐? 대박날텐데 \n",
       "53                                             새로운 똥물결 \n",
       "54                특검 꺼내는거보니 국힘과구만 이재명 죽이기해서 지가 대통령 될려고 \n",
       "55         ㅋㅋㅋ 왜 자꾸 시험은 없앨라고 하냐ㅋㅋㅋㅋ 시험이 제일 공정한 수단인데 ㅋㅋ \n",
       "56    행시폐지하고,, 또  인맥이나 재력으로 서로 밀어 주려고??  선진국등에서 이미 폐...\n",
       "57    똥팔육들 부들거리면서 달려드는거보면, 김동연 후보를 밀어줄만하다는 생각이 들기 시작...\n",
       "58              정확하게 방법을 제시했다. 누가되던 시행되었으면 하는 제도라고 본다… \n",
       "59    공무원 주민 점수제 두어서 3진 아웃하면 자동 퇴출하는법 도 만들어야한다, 관공서 ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLassn",
   "language": "python",
   "name": "dlassn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
